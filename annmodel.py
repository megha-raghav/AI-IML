# -*- coding: utf-8 -*-
"""ANNmodel.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-VxvMPvfAIXvpUjAaUGg5alsBDM3r4CP
"""

from google.colab import files
uploaded = files.upload()
for fn in uploaded.keys():
  print('user uploaded file "{name}" with length {length} bytes'.format(name=fn,length=len(uploaded[fn])))

import chardet
import pandas as pd
file = 'Car_Purchasing_Data.csv'
with open(file, 'rb') as rawdata:
    result = chardet.detect(rawdata.read(100000))
result
data= pd.read_csv(file,encoding='ISO-8859-1', delimiter=',', quotechar='"')
data.head()

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

x=data[[ "Gender", "Age","Annual Salary","Credit Card Debt", "Net Worth"]]
y=data["Car Purchase Amount"]


from sklearn.preprocessing import LabelEncoder
labelencoder_x_1=LabelEncoder()
y=labelencoder_x_1.fit_transform(y)


from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test=train_test_split(x,y,test_size =0.1,random_state=0)

from sklearn.preprocessing import StandardScaler
sc= StandardScaler()
x_train=sc.fit_transform(x_train)
x_test = sc.transform(x_test)

x_train

!pip install keras

import keras
from keras.models import Sequential
from keras.layers import Dense

classifier = Sequential()
classifier.add(Dense(3,kernel_initializer='glorot_uniform',activation='relu',input_dim=5))

classifier.add(Dense(3,kernel_initializer='glorot_uniform',activation='relu'))

classifier.add(Dense(1,kernel_initializer='glorot_uniform',activation='sigmoid'))

model=classifier.fit(x_train,y_train,batch_size=50,epochs=100)



x_test

